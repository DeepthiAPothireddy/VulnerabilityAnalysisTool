import urllib2, urllib, cookielib
from bs4 import BeautifulSoup
import requests
from urlparse import urljoin
import argparse
from collections import OrderedDict
from distutils.tests.setuptools_build_ext import if_dl
import re
import sys

#global variables initialized
urls_nvisited = []
urls_visited = []
postrequest_inurls = {}
postrequestwithtype = {}
nxsspostrequest_inurls = {}

# initial crawl
def crawl_website(location,input_url,forbiddenurls,cookie_dict = {},referer=False,urls_visited=[],urls_nvisited=[]):
    urls_incurrentpage = []
    inpage_formfields = []
    postrequest_file = location+'/output.txt'
    postrequesttype_file = location+'/postrequesttypename.txt'
    form_fields = ["date","email","number","tel","time","url","radio", "checkbox", "password", "file", "hidden","text"]
    if not input_url in urls_visited:
        urls_nvisited.append(input_url)
    while len(urls_nvisited) > 0:
        if not urls_nvisited[0] in urls_visited:
            current_page = urls_nvisited[0]
            urls_nvisited.pop(0)
        else:
            urls_nvisited.pop(0)
            continue
        print "Crawling:", current_page 
        urls_visited.append(current_page)
        try:
            # cookies in the crawler
            if not bool(cookie_dict):
                r = requests.get(current_page, verify=False)
            else:
                r = requests.get(current_page,verify=False,cookies=cookie_dict)
            # response text     
            page_content = r.text
        except:
            print "Could not access", current_page
            continue
        if not r.history:
            for c in r.cookies:
                cookie_dict[c.name] = c.value
        else:
            for response in r.history:
                for c in r.cookies:
                    cookie_dict[c.name] = c.value
        r.history= []
        # get page content
        html_pagecontent = BeautifulSoup(page_content)
        # if php script has window.location. 
        get_url = re.compile(r'window.location\s=\s"(.*)"',re.DOTALL).findall(str(html_pagecontent))
        for url in get_url:
            urls_incurrentpage.append(urljoin(current_page,url))
        # a href links in page content.
        atags_incurrentpage = html_pagecontent.find_all('a')
        for url_incurrentpage in atags_incurrentpage:
            if ('href' in dict(url_incurrentpage.attrs)):
                urls_incurrentpage.append(urljoin(current_page, url_incurrentpage['href']))
        # append new links in from page to nvisited.
        for new_link in urls_incurrentpage:
            if not new_link in urls_visited:
                urls_nvisited.append(new_link)
                urls_incurrentpage.pop(0) 
        # get form field names from current page response     
        form_field_names = html_pagecontent.findAll('input', {'type':form_fields})
        # check headers to find if xss is possible
        if not 'content-type' in r.headers:
            print("xss not possible")
        elif not 'text/html' in r.headers['content-type']:
            print("xss not possible")
        else:
            # add form fields to dictionary.
            print(current_page)
            if not current_page in forbiddenurls:
                postrequest_inurls[current_page] = []
                postrequestwithtype[current_page] = []
                for element in form_field_names:
#                     if 'name' in element:
                    postrequest_inurls[current_page].append(element['name'])
#                     if 'name' in element and 'type' in element:
                    elementnametype = element['name'] + ',' + element['type']
                    postrequestwithtype[current_page].append(elementnametype)
                    
                    
    #store values to output file and pass value to formfields
    for key,value in postrequest_inurls.iteritems():
        if not value=='':
            formfield = ','.join(value)
            with open(postrequest_file, 'a') as file_output:
                file_output.write(key + ',' + formfield +','+'\n')
    for key,value in postrequestwithtype.iteritems():
        if not value=='':
            formfield = ','.join(value)
            with open(postrequesttype_file, 'a') as file_output:
                file_output.write(key + ',' + formfield +','+'\n')
    return urls_visited, postrequest_inurls, cookie_dict
